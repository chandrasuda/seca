# Omni-Teacher: SDFT + SDPO for Code Generation

model:
  name: "deepseek-ai/deepseek-coder-1.3b-instruct"
  dtype: "bfloat16"
  max_len: 2048

training:
  mode: "omni"                # sft | sdft | sdpo | omni | grpo
  lr: 1e-5
  num_epochs: 3
  num_samples: 4              # K on-policy rollouts per problem
  max_grad_norm: 1.0
  checkpoint_dir: "checkpoints/"
  eval_every_epoch: 1

# Shared distillation temperatures (used by sdft, sdpo, omni sub-operators)
sdft: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 0.5 }
sdpo: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 0.5 }

omni:
  alpha_sdft: 0.4             # L = α·KL_sdft + β·KL_sdpo + γ·NLL_gold
  beta_sdpo: 0.4
  gamma_nll: 0.2
  sdft: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 1.0 }
  sdpo: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 1.0 }

data:
  dataset: "apps"             # apps | livecodebench | kernelbench
  split: "test"
  difficulty: "introductory"  # apps only
  max_problems: 100

eval:
  n_samples: 10
  k_values: [1, 5, 10]
  temperature: 0.8
  log_dir: "logs/"

seed: 42
