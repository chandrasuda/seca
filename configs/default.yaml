# Omni-Teacher: SDFT + SDPO for Code Generation

model:
  name: "deepseek-ai/deepseek-coder-1.3b-instruct"
  dtype: "bfloat16"
  max_len: 2048

training:
  mode: "omni"                # sft | sdft | sdpo | omni | grpo
  lr: 1e-6                   # SDPO paper Table 12
  weight_decay: 0.01         # SDPO paper Table 12
  num_epochs: 3
  num_samples: 4             # K on-policy rollouts per problem
  max_grad_norm: 1.0         # SDPO paper Table 12
  ema_alpha: 0.01            # EMA teacher: ϕ ← 0.99·ϕ + 0.01·θ
  checkpoint_dir: "checkpoints/"
  eval_every_epoch: 1

# SDFT: topk=100 per description
sdft: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 0.5, topk: 100 }

# SDPO: topk=20 per SDPO paper Table 12
sdpo: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 0.5, topk: 20 }

omni:
  alpha_sdft: 0.4            # L = α·KL_sdft + β·KL_sdpo + γ·NLL_gold
  beta_sdpo: 0.4
  gamma_nll: 0.2
  sdft: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 1.0, topk: 100 }
  sdpo: { temperature_student: 1.0, temperature_teacher: 0.7, kl_weight: 1.0, topk: 20 }

data:
  dataset: "apps"             # apps | livecodebench | kernelbench
  split: "test"
  difficulty: "introductory"  # apps only
  max_problems: 100

eval:
  n_samples: 10
  k_values: [1, 5, 10]
  temperature: 0.8
  log_dir: "logs/"

seed: 42
